{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed6XIWznqXLj"
      },
      "source": [
        "#ONE CLICK SETup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOOxDeVfqcE0",
        "outputId": "76e4a864-ff42-4778-e8fd-0434e2b4b6ed"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OqgjTKyqesh",
        "outputId": "685dcdf9-718a-45fb-b590-14ffa78d92bd"
      },
      "outputs": [],
      "source": [
        "!pip install -U ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ShcDNw-oqiyO"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3rmmB99hwD",
        "outputId": "54bb4597-2ad8-4054-bfeb-c24976b0ec3c"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics opencv-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KklyPEFly9cv"
      },
      "source": [
        "#Code to load Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDaBn64kvQSG",
        "outputId": "7c98e6a1-772b-4b26-a36d-b18558937f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cruePNzDuf"
      },
      "source": [
        "#Code to extract data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b285O5mUvz_I",
        "outputId": "df7a595f-ccce-4985-b70f-91e0c4ec8923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mNeural_Ocean_extracted\u001b[0m/  Neural_Ocean.v3i.yolov11.zip\n"
          ]
        }
      ],
      "source": [
        "ls drive/MyDrive/AI_IMAGE_PROJECT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee267c4f",
        "outputId": "f4fb9426-1d7c-4984-b21d-e354de8cfc73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully extracted drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean.v3i.yolov11.zip to drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = 'drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean.v3i.yolov11.zip'\n",
        "extraction_path = 'drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "print(f'Successfully extracted {zip_file_path} to {extraction_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRGOdKkN3xre",
        "outputId": "b77e8edd-1695-4197-c233-437915ba6f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgH0duCQ2pGV"
      },
      "source": [
        "#Dataset Drive: https://universe.roboflow.com/neural-ocean/neural_ocean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQdspJJVyl8l",
        "outputId": "13ec9c80-d011-4b96-f041-2be02bb36c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E49x7fmi_hk4"
      },
      "source": [
        "#library's required: ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e8ki1LGL3vf5",
        "outputId": "a67630cd-2f1f-473b-dad2-dfc8db8f85d6"
      },
      "outputs": [],
      "source": [
        "!pip install -U ultralytics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPpCZEYrALIs"
      },
      "source": [
        "#Analysis of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ffyLJGDVKC",
        "outputId": "d83bf8cf-1f4d-43af-cc6e-bb890b75648b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN: Images = 3626, Labels = 3626\n",
            "VALID: Images = 1000, Labels = 1000\n",
            "TEST: Images = 501, Labels = 501\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import os\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted\"\n",
        "\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = f\"{BASE_PATH}/{split}/images\"\n",
        "    lbl_dir = f\"{BASE_PATH}/{split}/labels\"\n",
        "\n",
        "    num_images = len(os.listdir(img_dir))\n",
        "    num_labels = len(os.listdir(lbl_dir))\n",
        "\n",
        "    print(f\"{split.upper()}: Images = {num_images}, Labels = {num_labels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-fvRFN8DdLK",
        "outputId": "18407764-4c51-4bf5-cee5-946a36b2cc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 15\n",
            "Classes: ['Mask', 'can', 'cellphone', 'electronics', 'gbottle', 'glove', 'metal', 'misc', 'net', 'pbag', 'pbottle', 'plastic', 'rod', 'sunglasses', 'tire']\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import yaml\n",
        "\n",
        "with open(f\"{BASE_PATH}/data.yaml\", \"r\") as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "class_names = data[\"names\"]\n",
        "num_classes = data[\"nc\"]\n",
        "\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Classes:\", class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua0htkESDhIk",
        "outputId": "e048e3e4-28c3-46eb-f423-1204480176d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution:\n",
            "\n",
            "Mask           : 1572\n",
            "can            : 163\n",
            "cellphone      : 385\n",
            "electronics    : 196\n",
            "gbottle        : 484\n",
            "glove          : 1261\n",
            "metal          : 83\n",
            "misc           : 257\n",
            "net            : 744\n",
            "pbag           : 1631\n",
            "pbottle        : 1342\n",
            "plastic        : 275\n",
            "rod            : 37\n",
            "sunglasses     : 18\n",
            "tire           : 3211\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "from collections import defaultdict\n",
        "\n",
        "class_count = defaultdict(int)\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    label_dir = f\"{BASE_PATH}/{split}/labels\"\n",
        "\n",
        "    for file in os.listdir(label_dir):\n",
        "        with open(os.path.join(label_dir, file), \"r\") as f:\n",
        "            for line in f:\n",
        "                cls_id = int(line.split()[0])\n",
        "                class_count[cls_id] += 1\n",
        "\n",
        "print(\"Class Distribution:\\n\")\n",
        "for cls_id, count in sorted(class_count.items()):\n",
        "    print(f\"{class_names[cls_id]:15s}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex8RKdH4Dw73",
        "outputId": "5925e499-f73b-4074-895f-6664c78bb1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg width: 416\n",
            "Avg height: 416\n",
            "Min resolution: 416 x 416\n",
            "Max resolution: 416 x 416\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import cv2\n",
        "\n",
        "image_sizes = []\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    img_dir = f\"{BASE_PATH}/{split}/images\"\n",
        "\n",
        "    for img_name in os.listdir(img_dir):\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            h, w, _ = img.shape\n",
        "            image_sizes.append((w, h))\n",
        "\n",
        "widths = [w for w, h in image_sizes]\n",
        "heights = [h for w, h in image_sizes]\n",
        "\n",
        "print(\"Avg width:\", sum(widths)//len(widths))\n",
        "print(\"Avg height:\", sum(heights)//len(heights))\n",
        "print(\"Min resolution:\", min(widths), \"x\", min(heights))\n",
        "print(\"Max resolution:\", max(widths), \"x\", max(heights))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxT6P4exDzen",
        "outputId": "f7c4f957-ec61-4a12-e7c8-4c0d9143fd24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty label files: 0\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "empty_labels = []\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    label_dir = f\"{BASE_PATH}/{split}/labels\"\n",
        "\n",
        "    for file in os.listdir(label_dir):\n",
        "        file_path = os.path.join(label_dir, file)\n",
        "        if os.path.getsize(file_path) == 0:\n",
        "            empty_labels.append(file_path)\n",
        "\n",
        "print(\"Empty label files:\", len(empty_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRDzUdS8DQY1"
      },
      "source": [
        "#YOLOv11 description: https://docs.ultralytics.com/models/yolo11/#key-features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRV2S9o5C1ZZ"
      },
      "source": [
        "| Model          | Size    | Speed       | Accuracy | GPU/CPU Use | Best For                    |\n",
        "| -------------- | ------- | ----------- | -------- | ----------- | --------------------------- |\n",
        "| **yolo11n.pt** | Nano    | ðŸš€ Fastest  | â­ Lowest | Very low    | Edge devices, quick tests   |\n",
        "| **yolo11s.pt** | Small   | âš¡ Very fast | â­â­       | Low         | Real-time apps              |\n",
        "| **yolo11m.pt** | Medium  | âš– Balanced  | â­â­â­â­     | Medium      | Best overall choice         |\n",
        "| **yolo11l.pt** | Large   | ðŸ¢ Slower   | â­â­â­â­â­    | High        | High accuracy tasks         |\n",
        "| **yolo11x.pt** | X-Large | ðŸŒ Slowest  | â­â­â­â­â­â­   | Very high   | Research / maximum accuracy |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvqusxKIEwYk"
      },
      "source": [
        "#Training with pretrained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "09sDHdpw_kME",
        "outputId": "290859a7-a780-454f-e1d3-df34ab0f4d97"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "DATA_YAML = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted/data.yaml\"\n",
        "\n",
        "#TODO: dont use pre-trained model, make it from scratch\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=80,\n",
        "    imgsz=416,\n",
        "    batch=16,            # â¬…ï¸ safer for CPU\n",
        "    device=\"cpu\",        # âœ… FIX\n",
        "    workers=4,           # â¬…ï¸ CPU-friendly\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.002,\n",
        "    cos_lr=True,\n",
        "    patience=15,\n",
        "    augment=True,\n",
        "\n",
        "    project=\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results\",\n",
        "    name=\"yolov11n_416_baseline\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pOECpgrj9tO"
      },
      "source": [
        "Validation Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_TQw-zuwFIO3",
        "outputId": "bcb32a3b-9dc3-4d65-a9b0-f10d62662223"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_baseline/weights/best.pt\")\n",
        "model.val()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQTjkUqWj-rv"
      },
      "source": [
        "code to Resume Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppfTcIC6hxXb"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load last checkpoint\n",
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_baseline/weights/last.pt\")\n",
        "\n",
        "# Resume training\n",
        "model.train(\n",
        "    resume=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-xWmmkhPfAs"
      },
      "source": [
        "#Training without pretrained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2uJjmYVka55",
        "outputId": "b1ebbe03-891c-41fa-f200-0a370cf67681"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nBE8-97aPhqF",
        "outputId": "e4ff9388-43af-4461-cda8-44b66febe2ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "DATA_YAML = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/Neural_Ocean_extracted/data.yaml\"\n",
        "\n",
        "# Load YOLOv11 Nano ARCHITECTURE ONLY (no pretrained weights)\n",
        "model = YOLO(\"yolo11n.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fuol0g7PmT5",
        "outputId": "e4332b7a-0192-4757-ccb6-5492b29ddd0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO11n summary: 182 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(182, 2624080, 2624064, 6.614336)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NX6NvtJoP1hS",
        "outputId": "d3e4bfa1-1a5e-4793-ef90-b6128c49e016"
      },
      "outputs": [],
      "source": [
        "print(model.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_NvMBlhzxTM"
      },
      "source": [
        "1 to 27 epoches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_-eIcX_xQaKY",
        "outputId": "a4a81fbe-ee74-4b5d-caa1-85189dfc685a"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Train the model FROM SCRATCH\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "\n",
        "    # Training duration\n",
        "    epochs=120,          # more epochs needed without pretraining\n",
        "\n",
        "    # Image & batch settings\n",
        "    imgsz=416,\n",
        "    batch=16,\n",
        "    device=\"cpu\",\n",
        "    workers=4,\n",
        "\n",
        "    # Optimisation\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.003,           # higher LR for training from scratch\n",
        "    cos_lr=True,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "\n",
        "    # Regularisation & robustness\n",
        "    augment=True,\n",
        "    patience=25,\n",
        "\n",
        "    # Saving results\n",
        "    project=\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results\",\n",
        "    name=\"yolov11n_416_from_scratch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss7F5tnYAlvM"
      },
      "source": [
        "#if (Resume Training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESlLXlDQ0D16"
      },
      "source": [
        "28 to 55"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gs1VmyN1AT-6",
        "outputId": "b3368e48-f41a-4df2-ee7c-b65bf9860588"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/last.pt\")\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xak0nE_y0NOI"
      },
      "source": [
        "56 to 83"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2xynVLHAzeGB",
        "outputId": "b4eac6d3-fd4b-48a7-96c0-b22e70470a66"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/last.pt\")\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oelrwhIdZNxG"
      },
      "source": [
        "84 to 86"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yYIVq6XDZP5U",
        "outputId": "37a9fc4a-69a6-40ea-f97c-c66d10235df1"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/last.pt\")\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lqQqR-cuTSX"
      },
      "source": [
        "87 to 97\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "fcdf4FbFuUo0",
        "outputId": "a3266701-497f-4ff5-988a-e4d42f48bd9a"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/last.pt\")\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyCjgbBNqSaE"
      },
      "source": [
        "98 to 106"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QXrE46qVqRwL",
        "outputId": "17c8cf21-0ea7-402a-de19-4b46ca02386e"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/last.pt\")\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XluV81Laboic"
      },
      "source": [
        "107 to 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "61CbwQfPbqJk",
        "outputId": "7ba4535a-e569-46aa-80ba-fe49c9cf0093"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/last.pt\")\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHt2n-ldAseM"
      },
      "source": [
        "#After Training (MANDATORY FOR REPORT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s5klGk3PAvWB",
        "outputId": "1de30502-fccd-487f-988f-c9d211f4b988"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/best.pt\")\n",
        "model.val()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLQ8Sd9T9dUj"
      },
      "source": [
        "#RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VFTf8NAv9eUI"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def take_photo():\n",
        "    js_code = '''\n",
        "    async function takePhoto() {\n",
        "        const video = document.createElement('video');\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        document.body.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        await new Promise(resolve => setTimeout(resolve, 1000));\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "        video.remove();\n",
        "\n",
        "        return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    }\n",
        "    takePhoto();\n",
        "    '''\n",
        "\n",
        "    data = eval_js(js_code)\n",
        "    img = b64decode(data.split(',')[1])\n",
        "    frame = cv2.imdecode(np.frombuffer(img, np.uint8), cv2.IMREAD_COLOR)\n",
        "    return frame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ZFMD3CZo-BqP",
        "outputId": "f9546420-c2a8-41bf-941b-9131332bca6a"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/best.pt\"\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "while True:\n",
        "    print(\"ðŸ“¸ Capturing frame...\")\n",
        "    frame = take_photo()\n",
        "\n",
        "    results = model.predict(\n",
        "        source=frame,\n",
        "        imgsz=416,\n",
        "        conf=0.25,\n",
        "        device=\"cpu\",\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    annotated = results[0].plot()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    if input(\"Press Enter for next frame or type 'q' to quit: \").lower() == 'q':\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDtqeFjjVseL"
      },
      "source": [
        "#RUN 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LoKSOwR-F69",
        "outputId": "c23dfb54-386e-44ac-97c9-1194511fa656"
      },
      "outputs": [],
      "source": [
        "ls drive/MyDrive/AI_IMAGE_PROJECT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPXNch-vVxeV"
      },
      "outputs": [],
      "source": [
        "VIDEO_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/Plastic Waste In The Sea Stock Video.mp4\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/best.pt\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/video_results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7rmFfCn9WSow",
        "outputId": "a1754927-026b-4d23-f337-5c9be11da934"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Load model\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# Run inference on video\n",
        "results = model.predict(\n",
        "    source=VIDEO_PATH,\n",
        "    imgsz=416,\n",
        "    conf=0.25,\n",
        "    device=\"cpu\",      # Colab CPU safe\n",
        "    save=True,         # Save output video\n",
        "    project=OUTPUT_DIR,\n",
        "    name=\"yolov11_video_detection2\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UaUFNPaWf6Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqF_zsg8YYmN"
      },
      "source": [
        "#RUN 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8LtTC9LGYZnD"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcm9ZAwKYhvV",
        "outputId": "6bd63c0e-3c20-4283-c918-df128051313a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Garbage underwater - zero wildlife.mp4'\n",
            " \u001b[0m\u001b[01;34mNeural_Ocean_extracted\u001b[0m/\n",
            " Neural_Ocean.v3i.yolov11.zip\n",
            "'Plastic Waste In The Sea Stock Video.mp4'\n",
            " \u001b[01;34mresults\u001b[0m/\n",
            " \u001b[01;34mvideo_results\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls drive/MyDrive/AI_IMAGE_PROJECT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9m84oVinYb6U"
      },
      "outputs": [],
      "source": [
        "# VIDEO_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/Plastic Waste In The Sea Stock Video.mp4\"\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/Garbage underwater - zero wildlife.mp4\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/AI_IMAGE_PROJECT/results/yolov11n_416_from_scratch/weights/best.pt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jvQzpoPrYdNB"
      },
      "outputs": [],
      "source": [
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "frame_count = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "86ooLICqYogK",
        "outputId": "86ca7703-75c6-4f20-9721-25e2cd924b2f"
      },
      "outputs": [],
      "source": [
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # YOLO inference on single frame\n",
        "    results = model(\n",
        "        frame,\n",
        "        imgsz=416,\n",
        "        conf=0.25,\n",
        "        device=\"cpu\"\n",
        "    )\n",
        "\n",
        "    # Draw predictions\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Show every Nth frame to avoid overload\n",
        "    if frame_count % 1 == 0:   # change to 1 for every frame\n",
        "        print(f\"Frame: {frame_count}\")\n",
        "        cv2_imshow(annotated_frame)\n",
        "\n",
        "cap.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLUio3OMYqS7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ed6XIWznqXLj",
        "KklyPEFly9cv",
        "D-cruePNzDuf",
        "bgH0duCQ2pGV",
        "E49x7fmi_hk4",
        "hPpCZEYrALIs",
        "dRDzUdS8DQY1",
        "jvqusxKIEwYk",
        "w-xWmmkhPfAs",
        "ss7F5tnYAlvM",
        "tHt2n-ldAseM",
        "KLQ8Sd9T9dUj",
        "CDtqeFjjVseL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
